{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "I2ao-X2iIsir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659996da-e791-4dc4-a2ef-722deef13832"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import textwrap\n",
        "\n",
        "# Constants\n",
        "MODEL_NAME = \"Vamsi/T5_Paraphrase_Paws\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def paraphrase_partial_range(\n",
        "    paragraph: str,\n",
        "    start_index: int,\n",
        "    end_index: int,\n",
        "    max_input_length: int = 512,\n",
        "    max_output_length: int = 400,\n",
        "    top_k: int = 120,\n",
        "    top_p: float = 0.95,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Paraphrases a specific word range within a paragraph and leaves the rest unchanged.\n",
        "\n",
        "    Args:\n",
        "        paragraph (str): Input paragraph.\n",
        "        start_index (int): Start word index (inclusive).\n",
        "        end_index (int): End word index (exclusive).\n",
        "        max_input_length (int): Max token length for encoder.\n",
        "        max_output_length (int): Max token length for decoder output.\n",
        "        top_k (int): Top-k sampling for diversity.\n",
        "        top_p (float): Top-p (nucleus) sampling for diversity.\n",
        "\n",
        "    Returns:\n",
        "        str: Partially paraphrased paragraph.\n",
        "    \"\"\"\n",
        "    words = paragraph.strip().split()\n",
        "\n",
        "    if start_index < 0 or end_index > len(words) or start_index >= end_index:\n",
        "        raise ValueError(\"Invalid start or end index for paraphrasing range.\")\n",
        "\n",
        "    # Split paragraph into three parts\n",
        "    before = \" \".join(words[:start_index])\n",
        "    to_paraphrase = \" \".join(words[start_index:end_index])\n",
        "    after = \" \".join(words[end_index:])\n",
        "\n",
        "    # Prepare input prompt\n",
        "    prompt = f\"paraphrase: {to_paraphrase} </s>\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # Generate paraphrased text\n",
        "    output = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=max_output_length,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "\n",
        "    paraphrased_part = tokenizer.decode(\n",
        "        output[0],\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "    )\n",
        "\n",
        "    # Combine original and paraphrased parts\n",
        "    parts = []\n",
        "    if before:\n",
        "        parts.append(before)\n",
        "    parts.append(paraphrased_part)\n",
        "    if after:\n",
        "        parts.append(after)\n",
        "\n",
        "    return \" \".join(parts).strip()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_paragraph = (\n",
        "       \"\"\" The Supply Chain Environmental Transformation plan 2024-2027 contains the mandatory chemical management requirements for the period 2024-2027.\n",
        "         Those requirements will be added to the current methane chlorophloro carbon minimum requirements covered by the Green to Wear standard:\n",
        "         (https://www.inditex.com/itxcomweb/api/media/0176de52-5436-46dc-9490-c91351b71cdd/GTW%202.1%20English%202023.pdf?t=1741164770911).\n",
        "         According to the on-site diagnosis, the level of compliance with the new chemical requirements 2024-2027 are given as follows:\"\"\"\n",
        "\n",
        "    )\n",
        "    # Customize the word index range here\n",
        "    start = 0\n",
        "    end = 40\n",
        "\n",
        "    result = paraphrase_partial_range(input_paragraph, start, end)\n",
        "\n",
        "    print(\"\\nüîπ Original Paragraph:\\n\", input_paragraph.strip())\n",
        "    print(f\"\\n‚úÖ Paraphrased from word {start} to {end}:\\n\", textwrap.fill(result.strip(), width=150))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PNcYAhQ07un",
        "outputId": "43e702d7-cf25-479e-fd51-be3888bef366"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Original Paragraph:\n",
            " The Supply Chain Environmental Transformation plan 2024-2027 contains the mandatory chemical management requirements for the period 2024-2027.\n",
            "         Those requirements will be added to the current methane chlorophloro carbon minimum requirements covered by the Green to Wear standard:\n",
            "         (https://www.inditex.com/itxcomweb/api/media/0176de52-5436-46dc-9490-c91351b71cdd/GTW%202.1%20English%202023.pdf?t=1741164770911).\n",
            "         According to the on-site diagnosis, the level of compliance with the new chemical requirements 2024-2027 are given as follows:\n",
            "\n",
            "‚úÖ Paraphrased from word 0 to 40:\n",
            " The 2024-2027 Supply Chain Environmental Transformation Plan contains the mandatory chemical management requirements for the 2024-2027 period, adding\n",
            "to the current methane chlorophlorocarbon minimum requirements from the Green to Wear standard\n",
            "(https://www.inditex.com/itxcomweb/api/media/0176de52-5436-46dc-9490-c91351b71cdd/GTW%202.1%20English%202023.pdf?t=1741164770911). the on-site\n",
            "diagnosis, the level of compliance with the new chemical requirements 2024-2027 are given as follows:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OrSrvrO3eaV",
        "outputId": "abcad3ea-5975-4939-d751-7b97a3666dac"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import textwrap\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download NLTK punkt tokenizer if not already available\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Constants\n",
        "MODEL_NAME = \"Vamsi/T5_Paraphrase_Paws\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def paraphrase_chunk(\n",
        "    text: str,\n",
        "    max_input_length: int = 512,\n",
        "    max_output_length: int = 512,\n",
        "    top_k: int = 120,\n",
        "    top_p: float = 0.95,\n",
        ") -> str:\n",
        "    \"\"\"Paraphrase a single text chunk.\"\"\"\n",
        "    prompt = f\"paraphrase: {text.strip()} </s>\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=max_output_length,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "\n",
        "def paraphrase_full_text(paragraph: str) -> str:\n",
        "    \"\"\"Split long paragraph and paraphrase it chunk by chunk.\"\"\"\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    paraphrased_sentences = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        try:\n",
        "            paraphrased = paraphrase_chunk(sent)\n",
        "            paraphrased_sentences.append(paraphrased)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error paraphrasing: {sent[:60]}... ‚Üí {e}\")\n",
        "            paraphrased_sentences.append(sent)  # fallback to original\n",
        "\n",
        "    return \" \".join(paraphrased_sentences).strip()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_paragraph = (\n",
        "        \"\"\"The Supply Chain Environmental Transformation plan 2024-2027 contains the mandatory chemical management requirements for the period 2024-2027.\n",
        "        Those requirements will be added to the current methane chlorophloro carbon minimum requirements covered () by the Green to Wear standard:\n",
        "        (https://www.inditex.com/itxcomweb/api/media/0176de52-5436-46dc-9490-c91351b71cdd/GTW%202.1%20English%202023.pdf?t=1741164770911).\n",
        "        According to the on-site diagnosis, the level of compliance with the new chemical requirements 2024-2027 are given as follows:\"\"\"\n",
        "    )\n",
        "\n",
        "    result = paraphrase_full_text(input_paragraph)\n",
        "\n",
        "    print(\"\\nüîπ Original Paragraph:\\n\")\n",
        "    print(textwrap.fill(input_paragraph.strip(), width=150))\n",
        "\n",
        "    print(\"\\n‚úÖ Paraphrased Full Paragraph:\\n\")\n",
        "    print(textwrap.fill(result.strip(), width=150))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6iQeNYt2NW-",
        "outputId": "91bf454b-39c1-4817-9f9e-5ebe40a21bf6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Original Paragraph:\n",
            "\n",
            "The Supply Chain Environmental Transformation plan 2024-2027 contains the mandatory chemical management requirements for the period 2024-2027.\n",
            "Those requirements will be added to the current methane chlorophloro carbon minimum requirements covered by the Green to Wear standard:\n",
            "(https://www.inditex.com/itxcomweb/api/media/0176de52-5436-46dc-9490-c91351b71cdd/GTW%202.1%20English%202023.pdf?t=1741164770911).         According\n",
            "to the on-site diagnosis, the level of compliance with the new chemical requirements 2024-2027 are given as follows:\n",
            "\n",
            "‚úÖ Paraphrased Full Paragraph:\n",
            "\n",
            "The 2024-2027 Supply Chain Environmental Transformation Plan contains mandatory chemical management requirements for the period 2024-2027. Those\n",
            "requirements will be added to the current minimum chlorophloro carbon requirements that are covered in the Green to Wear Standard:\n",
            "(https://www.inditex.com/itxcomweb/api/media/0176de52-5436-46dc-9490-c91351b71cdd/GTW%202.1%20English%202023.pdf?t=174116477091 ). According to the\n",
            "on-site diagnosis, the compliance with the new Chemical requirements for 2024-2027 are given as follows:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3stWAyN2U5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}